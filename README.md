# Deep Learning Tutorials

To teach others and myself the basics of deep learning I have compiled and created some resources to assist anyone looking to learn more about deep learning and all of its quirks. 

The repo will consist of sparsely organized materials others and I have developed but below is my reccomended order of reading in order to get the most out of the material.

## Probability and Linear Algebra Review
In any machine learning algorithm it is important to know your basic probability and linear algebra and this is true of deep learning as well. To get you caught up with the basics below are some resources and notebooks that I and others have used with great success
- [Gilbert Strang Linear Algebra](http://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/)
- [Matrix Cookbook](http://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)
- [Stanford Probability Review](http://web.stanford.edu/class/cme308/OldWebsite/notes/chap2.pdf)
- [MIT Probability Course](http://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/)

## Intro to Neural Networks
I have put together a notebook of notes that gives a quick introduction to neural networks. In those notebooks there are also references to other resources that will be good for ones first dive into neural networks and deep learning.

[Neural Network Introduction](neural_network_intro.ipynb)

A good resource for a quick introduction would be Geoffry Hintons [online course](https://class.coursera.org/neuralnets-2012-001/lecture) on neural networks. In particular lectures 1-6 are excelent introductory material.

## Backpropogation
Probably the hardest part of deep learning to understand but also the most important. If you ever wish to add your own layer types, work on improving efficiency of networks, or do pretty much anything with deep networks it is important to understand the training process which is called backpropogation. I highly reccomend reading through all of the material below several times to ensure you know the material well. Replicating any of the work below would also be a good exercise to test your knowledge.

[Backpropogation Tutorial](backprop_tutorial.ipynb)

[Geoffry Hintons Course](https://class.coursera.org/neuralnets-2012-001)

[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html)

## Deep Networks
Now that we are familiar with neural networks we can extend them into deep networks and explore their applications. I have provided an introductory Ipython Notebook to introduce a simple application of deep learning but more resources on why extending a neural network with deeper connections of layers gives favorable performance are given below as well.

[Deep Learning Tutorial](deep_learning_intro.ipynb)

[To go deep or wide in learning?](http://jmlr.org/proceedings/papers/v33/pandey14.pdf)

[Going Deeper with Convolutions](http://arxiv.org/pdf/1409.4842v1.pdf)

[Very Deep Convolutional Networks for Large Scale Image Recognition](http://arxiv.org/pdf/1409.1556v6.pdf)

## Popular Libraries and Frameworks
- [Neon](http://neon.nervanasys.com/docs/latest/index.html)
- [Keras](http://keras.io/)
- [Caffe](https://github.com/BVLC/caffe)
- [Tensorflow](https://github.com/tensorflow/tensorflow)
- [CNTK](https://github.com/Microsoft/CNTK)
- [Lasagne](http://lasagne.readthedocs.org/en/latest/)
- [Numpy](Numpy_tutorial.ipynb)
- [scikit-learn](http://scikit-learn.org/stable/)

## Layers
As you might know already, there are a lot of different layers one can add to a deep network besides simple fully connected layers. The two most popular in the literature these days are convolutional layers and recurrent layers. Both of these are important as they add new abilities for deep networks to learn that simple fully connected layers cannot provide. Below are some important resources to read through to understand these different layer types.

## Applications and Literature
Deep learning is a booming field and has many applications. It would be impossible for me to cover them all so here is a list of applications and some important literature related to each of them.

#### Object Recognition
[ImageNet Classification with Deep Convolutional Neural Networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

#### Activity Recognition
[Sequential Deep Learning for Human Action Recognition](http://liris.cnrs.fr/Documents/Liris-5228.pdf)

[Learning Spatiotemporal Features with 3D Convolutional Networks](http://arxiv.org/pdf/1412.0767.pdf)
#### Speech Recognition and Translation
[Deep Neural Networks for Acoustic Modeling in Speech Recognition](http://cs224d.stanford.edu/papers/maas_paper.pdf)

[Speech Recognition with Deep Recurrent Neural Networks](http://www.cs.toronto.edu/~fritz/absps/RNN13.pdf)
#### Biometrics
[Deep Face Recognition](https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf)

[DeepFace: Closing the Gap to Human-Level Performance in Face Verification](https://research.facebook.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/)

## More Awesome Resources
- [Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning)
- [Awesome Deep Learning](https://github.com/ChristosChristofidis/awesome-deep-learning)
- [Awesome Recurrent Neural Networks](https://github.com/kjw0612/awesome-rnn)
- [Awesome Public Datasets](https://github.com/caesar0301/awesome-public-datasets)
